{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## QUICK REFERENCE CARD"
      ],
      "metadata": {
        "id": "euOVM7VJh9yQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbHq0Suoh7sI",
        "outputId": "44602ee4-0ba8-4e76-975b-29655af0ecee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "üìö PYTORCH CHEAT SHEET\n",
            "==================================================\n",
            "\n",
            "üß† Layers:\n",
            "------------------------------\n",
            "  ‚Ä¢ Linear: nn.Linear(in_features, out_features)\n",
            "  ‚Ä¢ Conv2d: nn.Conv2d(in_channels, out_channels, kernel_size)\n",
            "  ‚Ä¢ LSTM: nn.LSTM(input_size, hidden_size, num_layers)\n",
            "  ‚Ä¢ Dropout: nn.Dropout(p=0.5)\n",
            "  ‚Ä¢ BatchNorm: nn.BatchNorm2d(num_features)\n",
            "\n",
            "‚ö° Activations:\n",
            "------------------------------\n",
            "  ‚Ä¢ ReLU: nn.ReLU() or F.relu(x)\n",
            "  ‚Ä¢ Sigmoid: nn.Sigmoid() or torch.sigmoid(x)\n",
            "  ‚Ä¢ Tanh: nn.Tanh() or torch.tanh(x)\n",
            "  ‚Ä¢ Softmax: nn.Softmax(dim=1) or F.softmax(x, dim=1)\n",
            "\n",
            "üìâ Loss Functions:\n",
            "------------------------------\n",
            "  ‚Ä¢ BCE: nn.BCELoss() (Binary Cross Entropy)\n",
            "  ‚Ä¢ CrossEntropy: nn.CrossEntropyLoss() (multi-class)\n",
            "  ‚Ä¢ MSE: nn.MSELoss() (Regression)\n",
            "  ‚Ä¢ L1: nn.L1Loss() (MAE)\n",
            "\n",
            "‚öôÔ∏è Optimizers:\n",
            "------------------------------\n",
            "  ‚Ä¢ SGD: optim.SGD(model.parameters(), lr=0.01)\n",
            "  ‚Ä¢ Adam: optim.Adam(model.parameters(), lr=0.001)\n",
            "  ‚Ä¢ RMSprop: optim.RMSprop(model.parameters(), lr=0.01)\n",
            "\n",
            "üîß Essential Operations:\n",
            "------------------------------\n",
            "  ‚Ä¢ Zero Grad: optimizer.zero_grad()\n",
            "  ‚Ä¢ Backward: loss.backward()\n",
            "  ‚Ä¢ Step: optimizer.step()\n",
            "  ‚Ä¢ Detach: x.detach() (remove from computation graph)\n",
            "  ‚Ä¢ To GPU: model.cuda() or tensor.cuda()\n",
            "\n",
            "üõ°Ô∏è Regularization:\n",
            "------------------------------\n",
            "  ‚Ä¢ L2: weight_decay in optimizer\n",
            "  ‚Ä¢ L1: Manual: torch.abs(weights).sum()\n",
            "  ‚Ä¢ Dropout: nn.Dropout(p)\n",
            "  ‚Ä¢ BatchNorm: Normalizes layer outputs\n",
            "\n",
            "==================================================\n",
            "üí° TIP: Always use .train() and .eval() modes properly!\n",
            "       .train() ‚Üí training mode (enables dropout)\n",
            "       .eval() ‚Üí evaluation mode (disables dropout)\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "def pytorch_cheat_sheet():\n",
        "    \"\"\"üìö PyTorch Quick Reference\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üìö PYTORCH CHEAT SHEET\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    cheat_sheet = {\n",
        "        \"üß† Layers\": {\n",
        "            \"Linear\": \"nn.Linear(in_features, out_features)\",\n",
        "            \"Conv2d\": \"nn.Conv2d(in_channels, out_channels, kernel_size)\",\n",
        "            \"LSTM\": \"nn.LSTM(input_size, hidden_size, num_layers)\",\n",
        "            \"Dropout\": \"nn.Dropout(p=0.5)\",\n",
        "            \"BatchNorm\": \"nn.BatchNorm2d(num_features)\"\n",
        "        },\n",
        "        \"‚ö° Activations\": {\n",
        "            \"ReLU\": \"nn.ReLU() or F.relu(x)\",\n",
        "            \"Sigmoid\": \"nn.Sigmoid() or torch.sigmoid(x)\",\n",
        "            \"Tanh\": \"nn.Tanh() or torch.tanh(x)\",\n",
        "            \"Softmax\": \"nn.Softmax(dim=1) or F.softmax(x, dim=1)\"\n",
        "        },\n",
        "        \"üìâ Loss Functions\": {\n",
        "            \"BCE\": \"nn.BCELoss() (Binary Cross Entropy)\",\n",
        "            \"CrossEntropy\": \"nn.CrossEntropyLoss() (multi-class)\",\n",
        "            \"MSE\": \"nn.MSELoss() (Regression)\",\n",
        "            \"L1\": \"nn.L1Loss() (MAE)\"\n",
        "        },\n",
        "        \"‚öôÔ∏è Optimizers\": {\n",
        "            \"SGD\": \"optim.SGD(model.parameters(), lr=0.01)\",\n",
        "            \"Adam\": \"optim.Adam(model.parameters(), lr=0.001)\",\n",
        "            \"RMSprop\": \"optim.RMSprop(model.parameters(), lr=0.01)\"\n",
        "        },\n",
        "        \"üîß Essential Operations\": {\n",
        "            \"Zero Grad\": \"optimizer.zero_grad()\",\n",
        "            \"Backward\": \"loss.backward()\",\n",
        "            \"Step\": \"optimizer.step()\",\n",
        "            \"Detach\": \"x.detach() (remove from computation graph)\",\n",
        "            \"To GPU\": \"model.cuda() or tensor.cuda()\"\n",
        "        },\n",
        "        \"üõ°Ô∏è Regularization\": {\n",
        "            \"L2\": \"weight_decay in optimizer\",\n",
        "            \"L1\": \"Manual: torch.abs(weights).sum()\",\n",
        "            \"Dropout\": \"nn.Dropout(p)\",\n",
        "            \"BatchNorm\": \"Normalizes layer outputs\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for category, items in cheat_sheet.items():\n",
        "        print(f\"\\n{category}:\")\n",
        "        print(\"-\" * 30)\n",
        "        for key, value in items.items():\n",
        "            print(f\"  ‚Ä¢ {key}: {value}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üí° TIP: Always use .train() and .eval() modes properly!\")\n",
        "    print(\"       .train() ‚Üí training mode (enables dropout)\")\n",
        "    print(\"       .eval() ‚Üí evaluation mode (disables dropout)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "# üìñ Display cheat sheet\n",
        "pytorch_cheat_sheet()"
      ]
    }
  ]
}